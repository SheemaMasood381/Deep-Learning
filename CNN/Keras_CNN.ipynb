{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ“Œ Image Classification with Pretrained CNN Models in Keras\n",
        "\n",
        "In this notebook, we will perform image classification using three different pretrained Convolutional Neural Network (CNN) models:  \n",
        "- **ResNet50**  \n",
        "- **MobileNetV2**  \n",
        "- **EfficientNetB0**  \n",
        "\n",
        "These models are trained on the **ImageNet** dataset and can classify images into 1000 different object categories. Let's explore how to use them for predicting image labels!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Lu6eaZflZXSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ”¹ 1. Using ResNet50 for Image Classification\n",
        "\n",
        "### âœ… **Step 1: Import Required Libraries**"
      ],
      "metadata": {
        "id": "i0-hNLOXZfOH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZcTnCb8MG58r"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âœ… **Step 2: Load Pretrained ResNet50 Model**"
      ],
      "metadata": {
        "id": "t2OAOd8YZnDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUPrPs7wHB9f",
        "outputId": "bb84f20a-430c-4627-f4d6-fce24057d7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âœ… **Step 3: Load and Preprocess the Image**"
      ],
      "metadata": {
        "id": "HbE9YuVFZ1O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/elephant.jpg'\n",
        "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
        "x = keras.utils.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "metadata": {
        "id": "jpx4BIYpHIgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âœ… **Step 4: Make Predictions**"
      ],
      "metadata": {
        "id": "eOMigZYXZ5y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x)\n",
        "# decode the results into a list of tuples (class, description, probability)\n",
        "# (one such list for each sample in the batch)\n",
        "print('Predicted:', decode_predictions(preds, top=5)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2RJrvXXHJaw",
        "outputId": "a6e9d2e5-30db-4c68-e160-9a3563eee386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "Predicted: [('n02504458', 'African_elephant', 0.52369887), ('n01871265', 'tusker', 0.44379628), ('n02504013', 'Indian_elephant', 0.031687018), ('n01704323', 'triceratops', 0.0001904827), ('n02963159', 'cardigan', 7.371109e-05)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ”¹ **2. Using MobileNetV2 for Image Classification**\n",
        "### âœ… **Step 1: Import Required Libraries**"
      ],
      "metadata": {
        "id": "KXwLB6fOaBGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ],
      "metadata": {
        "id": "GNu1TZZ3IadO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âœ… **Step 2: Load Pretrained MobileNetV2 Model**"
      ],
      "metadata": {
        "id": "oyGmCmTraJC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained model\n",
        "model = MobileNetV2(weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLpT8i--Heco",
        "outputId": "8de530fa-39fb-4b7c-d8a6-92bad81d3a44"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "\u001b[1m14536120/14536120\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âœ… **Step 3: Define Image Preprocessing Function**"
      ],
      "metadata": {
        "id": "vt-q6jzhaNCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the image\n",
        "def prepare_image(image_path, target_size=(224, 224)):\n",
        "    image = load_img(image_path, target_size=target_size)  # Resize the image\n",
        "    image = img_to_array(image)                           # Convert to numpy array\n",
        "    image = np.expand_dims(image, axis=0)                 # Add batch dimension\n",
        "    image = preprocess_input(image)                       # Preprocess as per MobileNetV2\n",
        "    return image\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "dHUBQ2L9IXcF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âœ… **Step 4: Load and Preprocess the Image**"
      ],
      "metadata": {
        "id": "Qhvb5_0walM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Path to your image\n",
        "image_path = '/content/images (1).jpeg'\n",
        "\n",
        "# Prepare the image\n",
        "image = prepare_image(image_path)"
      ],
      "metadata": {
        "id": "L7y1LY4takd9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âœ… **Step 5: Make Predictions**"
      ],
      "metadata": {
        "id": "FAgvMJlhadd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the class\n",
        "predictions = model.predict(image)\n",
        "\n",
        "# Decode the predictions\n",
        "decoded_predictions = decode_predictions(predictions, top=5)  # Get top-5 predictions\n",
        "\n",
        "# Display predictions\n",
        "print(\"Predictions:\")\n",
        "for i, (imagenet_id, label, score) in enumerate(decoded_predictions[0]):\n",
        "    print(f\"{i + 1}: {label} ({score:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1lmP19yaeJe",
        "outputId": "13db8b70-c2ee-4598-dc31-846b91bb236e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Predictions:\n",
            "1: drilling_platform (0.10)\n",
            "2: crane (0.09)\n",
            "3: palace (0.07)\n",
            "4: fountain (0.06)\n",
            "5: stupa (0.05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ”¹ **3. Using EfficientNetB0 for Image Classification**\n",
        "### âœ… **Same workflow as above**"
      ],
      "metadata": {
        "id": "AGspIEMQeW3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Load the pre-trained EfficientNetB0 model\n",
        "model = EfficientNetB0(weights='imagenet')\n",
        "\n",
        "# Function to preprocess the image\n",
        "def prepare_image(image_path, target_size=(224, 224)):\n",
        "    # Load the image and resize to target dimensions\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    # Convert the image to a numpy array\n",
        "    image = img_to_array(image)\n",
        "    # Add batch dimension (1, height, width, channels)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    # Preprocess the image for EfficientNet\n",
        "    image = preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "# Path to the image file\n",
        "image_path = '/content/image.jpeg'\n",
        "\n",
        "# Prepare the image\n",
        "image = prepare_image(image_path)\n",
        "\n",
        "# Predict the class probabilities\n",
        "predictions = model.predict(image)\n",
        "\n",
        "# Decode the predictions into human-readable labels\n",
        "decoded_predictions = decode_predictions(predictions, top=5)\n",
        "\n",
        "# Print the predictions\n",
        "print(\"Top Predictions:\")\n",
        "for i, (imagenet_id, label, score) in enumerate(decoded_predictions[0]):\n",
        "    print(f\"{i + 1}: {label} ({score:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys8j8DaZIgAE",
        "outputId": "bc819a1f-a752-41af-da61-10e57cdb435c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0.h5\n",
            "\u001b[1m21834768/21834768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Top Predictions:\n",
            "1: lakeside (0.22)\n",
            "2: bell_cote (0.08)\n",
            "3: seashore (0.06)\n",
            "4: obelisk (0.04)\n",
            "5: palace (0.04)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“Œ Conclusion\n",
        "We successfully classified images using three different state-of-the-art models:\n",
        "\n",
        "âœ… ResNet50 - A deep and powerful network with high accuracy.\n",
        "\n",
        "âœ… MobileNetV2 - A lightweight model optimized for mobile devices.\n",
        "\n",
        "âœ… EfficientNetB0 - A highly efficient and accurate model.\n",
        "\n",
        "\n",
        "Each model has its own advantages, and the best choice depends on your specific requirements (speed, accuracy, or size). ğŸ¯"
      ],
      "metadata": {
        "id": "dNpPNmH9eyeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------"
      ],
      "metadata": {
        "id": "6BJYhp9SfFuq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e9WfeXe-Jg-s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}